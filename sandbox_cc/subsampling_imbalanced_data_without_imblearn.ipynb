{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    " \n",
    "def test_gini():\n",
    "    def fequ(a,b):\n",
    "        return abs( a -b) < 1e-6\n",
    "    def T(a, p, g, n):\n",
    "        assert( fequ(gini(a,p), g) )\n",
    "        assert( fequ(gini_normalized(a,p), n) )\n",
    "    T([1, 2, 3], [10, 20, 30], 0.111111, 1)\n",
    "    T([1, 2, 3], [30, 20, 10], -0.111111, -1)\n",
    "    T([1, 2, 3], [0, 0, 0], -0.111111, -1)\n",
    "    T([3, 2, 1], [0, 0, 0], 0.111111, 1)\n",
    "    T([1, 2, 4, 3], [0, 0, 0, 0], -0.1, -0.8)\n",
    "    T([2, 1, 4, 3], [0, 0, 2, 1], 0.125, 1)\n",
    "    T([0, 20, 40, 0, 10], [40, 40, 10, 5, 5], 0, 0)\n",
    "    T([40, 0, 20, 0, 10], [1000000, 40, 40, 5, 5], 0.171428,\n",
    "      0.6)\n",
    "    T([40, 20, 10, 0, 0], [40, 20, 10, 0, 0], 0.285714, 1)\n",
    "    T([1, 1, 0, 1], [0.86, 0.26, 0.52, 0.32], -0.041666,\n",
    "      -0.333333)\n",
    "    \n",
    "test_gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'target', u'ps_ind_01', u'ps_ind_02_cat', u'ps_ind_03',\n",
       "       u'ps_ind_04_cat', u'ps_ind_05_cat', u'ps_ind_06_bin', u'ps_ind_07_bin',\n",
       "       u'ps_ind_08_bin', u'ps_ind_09_bin', u'ps_ind_10_bin', u'ps_ind_11_bin',\n",
       "       u'ps_ind_12_bin', u'ps_ind_13_bin', u'ps_ind_14', u'ps_ind_15',\n",
       "       u'ps_ind_16_bin', u'ps_ind_17_bin', u'ps_ind_18_bin', u'ps_reg_01',\n",
       "       u'ps_reg_02', u'ps_reg_03', u'ps_car_01_cat', u'ps_car_02_cat',\n",
       "       u'ps_car_03_cat', u'ps_car_04_cat', u'ps_car_05_cat', u'ps_car_06_cat',\n",
       "       u'ps_car_07_cat', u'ps_car_08_cat', u'ps_car_09_cat', u'ps_car_10_cat',\n",
       "       u'ps_car_11_cat', u'ps_car_11', u'ps_car_12', u'ps_car_13',\n",
       "       u'ps_car_14', u'ps_car_15', u'ps_calc_01', u'ps_calc_02', u'ps_calc_03',\n",
       "       u'ps_calc_04', u'ps_calc_05', u'ps_calc_06', u'ps_calc_07',\n",
       "       u'ps_calc_08', u'ps_calc_09', u'ps_calc_10', u'ps_calc_11',\n",
       "       u'ps_calc_12', u'ps_calc_13', u'ps_calc_14', u'ps_calc_15_bin',\n",
       "       u'ps_calc_16_bin', u'ps_calc_17_bin', u'ps_calc_18_bin',\n",
       "       u'ps_calc_19_bin', u'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Default handling nan **\n",
    "\n",
    "For now, just use columns distribution to fill in empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_02_cat\n",
      "ps_ind_04_cat\n",
      "ps_ind_05_cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ubuntu_ve_2.9/lib/python2.7/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_reg_03\n",
      "ps_car_01_cat\n",
      "ps_car_02_cat\n",
      "ps_car_03_cat\n",
      "ps_car_05_cat\n",
      "ps_car_07_cat\n",
      "ps_car_09_cat\n",
      "ps_car_11\n",
      "ps_car_12\n",
      "ps_car_14\n"
     ]
    }
   ],
   "source": [
    "df_train.replace(-1, np.nan, inplace=True)\n",
    "null_vals = df_train.isnull().sum(axis=0)[df_train.isnull().sum(axis=0)>0]\n",
    "value_count_columns = {i: df_train[i].value_counts(1) for i in df_train.columns}    \n",
    "df_train_copy = df_train.copy()\n",
    "for c in df_train.columns:\n",
    "    total_num = df_train[c].isnull().sum()\n",
    "    if(total_num == 0):\n",
    "        continue\n",
    "    print(c)\n",
    "    \n",
    "    random_vals = np.random.choice(list(value_count_columns[c].index), total_num, list(value_count_columns[c].values))\n",
    "    \n",
    "    df_train_copy[c].loc[df_train[c].isnull()] = random_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target            0\n",
       "ps_ind_01         0\n",
       "ps_ind_02_cat     0\n",
       "ps_ind_03         0\n",
       "ps_ind_04_cat     0\n",
       "ps_ind_05_cat     0\n",
       "ps_ind_06_bin     0\n",
       "ps_ind_07_bin     0\n",
       "ps_ind_08_bin     0\n",
       "ps_ind_09_bin     0\n",
       "ps_ind_10_bin     0\n",
       "ps_ind_11_bin     0\n",
       "ps_ind_12_bin     0\n",
       "ps_ind_13_bin     0\n",
       "ps_ind_14         0\n",
       "ps_ind_15         0\n",
       "ps_ind_16_bin     0\n",
       "ps_ind_17_bin     0\n",
       "ps_ind_18_bin     0\n",
       "ps_reg_01         0\n",
       "ps_reg_02         0\n",
       "ps_reg_03         0\n",
       "ps_car_01_cat     0\n",
       "ps_car_02_cat     0\n",
       "ps_car_03_cat     0\n",
       "ps_car_04_cat     0\n",
       "ps_car_05_cat     0\n",
       "ps_car_06_cat     0\n",
       "ps_car_07_cat     0\n",
       "ps_car_08_cat     0\n",
       "ps_car_09_cat     0\n",
       "ps_car_10_cat     0\n",
       "ps_car_11_cat     0\n",
       "ps_car_11         0\n",
       "ps_car_12         0\n",
       "ps_car_13         0\n",
       "ps_car_14         0\n",
       "ps_car_15         0\n",
       "ps_calc_01        0\n",
       "ps_calc_02        0\n",
       "ps_calc_03        0\n",
       "ps_calc_04        0\n",
       "ps_calc_05        0\n",
       "ps_calc_06        0\n",
       "ps_calc_07        0\n",
       "ps_calc_08        0\n",
       "ps_calc_09        0\n",
       "ps_calc_10        0\n",
       "ps_calc_11        0\n",
       "ps_calc_12        0\n",
       "ps_calc_13        0\n",
       "ps_calc_14        0\n",
       "ps_calc_15_bin    0\n",
       "ps_calc_16_bin    0\n",
       "ps_calc_17_bin    0\n",
       "ps_calc_18_bin    0\n",
       "ps_calc_19_bin    0\n",
       "ps_calc_20_bin    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('null values')\n",
    "df_train_copy.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test full dataset without subsampling **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 58)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dist of 0/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Current dist of 0/1')\n",
    "df_train_copy['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('potentially_unnecessary_features.txt') as r:\n",
    "    features_to_remove = [l.strip() for l in r]\n",
    "\n",
    "cols_for_random_forest = list(set(df_train_copy.columns) - set(features_to_remove + ['target']))\n",
    "\n",
    "cols_for_lr = [\n",
    "    'ps_ind_16_bin', 'ps_ind_09_bin', 'ps_ind_01', 'ps_ind_08_bin', 'ps_ind_06_bin', \n",
    "    'ps_car_12', 'ps_ind_17_bin', 'ps_calc_02', 'ps_calc_03', 'ps_calc_01', 'ps_reg_02',\n",
    "    'ps_reg_03', 'ps_reg_01', 'ps_ind_04_cat', 'ps_car_07_cat', 'ps_car_02_cat', 'ps_car_11',\n",
    "    'ps_car_13', 'ps_car_15', 'ps_car_14', 'ps_ind_07_bin', 'ps_ind_02_cat', 'ps_ind_15', 'ps_car_09_cat', \n",
    "    'ps_car_08_cat', 'ps_ind_05_cat', 'ps_ind_18_bin'\n",
    "]\n",
    "\n",
    "cols_for_bc = [\n",
    "    u'ps_ind_09_bin', u'ps_ind_01', u'ps_ind_03', u'ps_ind_08_bin',\n",
    "    u'ps_ind_06_bin', u'ps_car_12', u'ps_ind_17_bin', u'ps_calc_03',\n",
    "    u'ps_reg_02', u'ps_reg_03', u'ps_calc_04', u'ps_reg_01',\n",
    "    u'ps_ind_04_cat', u'ps_calc_09', u'ps_car_07_cat', u'ps_car_02_cat',\n",
    "    u'ps_car_13', u'ps_ind_07_bin', u'ps_ind_02_cat', u'ps_ind_15',\n",
    "    u'ps_car_09_cat', u'ps_calc_07', u'ps_calc_13', u'ps_calc_14',\n",
    "    u'ps_car_06_cat', u'ps_calc_05', u'ps_car_08_cat', u'ps_ind_05_cat',\n",
    "    u'ps_ind_18_bin'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base.BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractFeatures(sklearn.base.BaseEstimator):\n",
    "    \"\"\"\n",
    "    simply remove the sets of features we want to use for a specific model\n",
    "    \"\"\"\n",
    "    def __init__(self, cols=[]):\n",
    "        \"\"\"\n",
    "        define which columns to extract from dataframe\n",
    "        \"\"\"\n",
    "        self.use_cols = cols\n",
    "    \n",
    "    #def get_params(self, deep=True):\n",
    "    #    return {\n",
    "    #        'cols': getattr(self, 'use_cols', None)\n",
    "    #    }\n",
    "    \n",
    "    def dummy_extract(self, dfX):\n",
    "        \"\"\"\n",
    "        extract cols and return as np.array\n",
    "        \"\"\"\n",
    "        return dfX[self.use_cols].values\n",
    "    def transform(self, dfX):\n",
    "        return self.dummy_extract(dfX)\n",
    "    def fit(self, dfX, _y):\n",
    "        self.dummy_extract(dfX)\n",
    "        return self\n",
    "\n",
    "def TestExtract():\n",
    "    a = pd.DataFrame({\n",
    "        'a': ['a', 'b', 'c'],\n",
    "        'b': ['d', 'e', 'f'],\n",
    "        'c': ['g', 'h', 'i'],\n",
    "    })\n",
    "    col = ['a', 'c']\n",
    "    assert ((a[col].values != ExtractFeatures(col).transform(a)).sum()==0)\n",
    "    col = ['a']\n",
    "    assert ((a[col].values != ExtractFeatures(col).transform(a)).sum()==0)\n",
    "    col = ['c']\n",
    "    assert ((a[col].values != ExtractFeatures(col).transform(a)).sum()==0)\n",
    "\n",
    "TestExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LINE OF CODE TO EXTRACT THE CODE FROM A MODULE\n",
    "# import inspect\n",
    "# lines = inspect.getsourcelines(StandardScaler)\n",
    "# print('\\n'.join(lines[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        ('extract', ExtractFeatures(cols_for_random_forest)),\n",
    "        ('rfc', RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=None, n_jobs=4))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        ('extract', ExtractFeatures(cols_for_lr)),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('lr', LogisticRegression(n_jobs=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_bc = Pipeline(\n",
    "    [\n",
    "        ('extract', ExtractFeatures(cols_for_bc)),        \n",
    "        ('bc', BaggingClassifier(\n",
    "                base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=100),\n",
    "                n_estimators=100,\n",
    "                max_features=1.0,\n",
    "                bootstrap=True,\n",
    "                bootstrap_features=True,\n",
    "                n_jobs=8\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively use train-test-split for now because easier to compare with the 'randomized' subsampling method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_train_copy, df_train_copy['target'], test_size=0.2\n",
    "    )\n",
    "    pipe_rf.fit(X_train, y_train)\n",
    "    rf_vals = pipe_rf.predict(X_test)\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "    lr_vals = pipe_lr.predict_proba(X_test)[:,1]# .max(axis=1)\n",
    "    pipe_bc.fit(X_train, y_train)\n",
    "    bc_vals = pipe_bc.predict(X_test)\n",
    "    acc.append({\n",
    "        'rf_gini': gini_normalized(y_test, rf_vals),\n",
    "        'lr_gini': gini_normalized(y_test, lr_vals),\n",
    "        'bc_gini': gini_normalized(y_test, bc_vals),\n",
    "        'averaged': gini_normalized(y_test, pd.DataFrame([rf_vals, lr_vals, bc_vals]).mean(axis=0))   \n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averaged</th>\n",
       "      <th>bc_gini</th>\n",
       "      <th>lr_gini</th>\n",
       "      <th>rf_gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.231304</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>-0.231304</td>\n",
       "      <td>0.005140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.255207</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.255207</td>\n",
       "      <td>-0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.228250</td>\n",
       "      <td>-0.006096</td>\n",
       "      <td>-0.228250</td>\n",
       "      <td>-0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.233070</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>-0.233070</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.231312</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>-0.231312</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.240506</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>-0.240506</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.246159</td>\n",
       "      <td>-0.023071</td>\n",
       "      <td>-0.246159</td>\n",
       "      <td>-0.023071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.251520</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.251520</td>\n",
       "      <td>-0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.252621</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>-0.252621</td>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.231274</td>\n",
       "      <td>-0.010510</td>\n",
       "      <td>-0.231274</td>\n",
       "      <td>-0.010510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   averaged   bc_gini   lr_gini   rf_gini\n",
       "0 -0.231304  0.005140 -0.231304  0.005140\n",
       "1 -0.255207 -0.000453 -0.255207 -0.000453\n",
       "2 -0.228250 -0.006096 -0.228250 -0.006096\n",
       "3 -0.233070  0.003540 -0.233070  0.003540\n",
       "4 -0.231312  0.001384 -0.231312  0.001384\n",
       "5 -0.240506  0.001478 -0.240506  0.001478\n",
       "6 -0.246159 -0.023071 -0.246159 -0.023071\n",
       "7 -0.251520 -0.000194 -0.251520 -0.000194\n",
       "8 -0.252621  0.001935 -0.252621  0.001935\n",
       "9 -0.231274 -0.010510 -0.231274 -0.010510"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_without_sub_sampling = pd.DataFrame(acc)\n",
    "acc_without_sub_sampling.to_pickle('acc_no_sub_sample.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to train on subsampled data**\n",
    "\n",
    "1. use train_test_split to create a training dataset and a testing dataset\n",
    "2. in the trainining dataset, subsample 10000 elements multiple times\n",
    "    * for each subset training data, fit to models\n",
    "3. for the testing set, predict using all models created from subsets\n",
    "4. evaluate gini coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 0)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 1)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 2)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 3)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 4)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 5)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 6)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 7)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 8)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('a', 9)\n",
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n"
     ]
    }
   ],
   "source": [
    "max_values = 10000\n",
    "acc_with_sub_samp = []\n",
    "\n",
    "for _ in range(10):\n",
    "    print('a', _)\n",
    "    X_train_for_sub, X_test_for_sub, y_train_for_sub, y_test_for_sub = train_test_split(\n",
    "        df_train_copy, df_train_copy['target'], test_size=0.2\n",
    "    )\n",
    "\n",
    "    all_subsets = []\n",
    "    all_models = []\n",
    "    for __ in range(10):\n",
    "        print('b', __)\n",
    "        # create series of subsampled datasets\n",
    "        assert ((X_train_for_sub.index != y_train_for_sub.index).sum() == 0)\n",
    "        sampled_indexes = np.hstack(list(pd.DataFrame(y_train_for_sub).groupby(by='target').apply(lambda x: x.sample(min(max_values, x.shape[0])).index)))\n",
    "\n",
    "        new_x_train = X_train_for_sub.loc[sampled_indexes]\n",
    "        new_y_train = y_train_for_sub.loc[sampled_indexes]\n",
    "        all_models.extend(\n",
    "            [\n",
    "                # train each subsampled model\n",
    "                pipe_rf.fit(new_x_train, new_y_train),\n",
    "                pipe_lr.fit(new_x_train, new_y_train),\n",
    "                pipe_bc.fit(new_x_train, new_y_train)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # fit data using all subsamples\n",
    "    all_predicted_vals_rf = pd.DataFrame([all_models[i].predict(X_test_for_sub) for i in range(0, len(all_models), 3)]).mean(axis=0)\n",
    "    # or choose argmax....??\n",
    "    all_predicted_vals_lr = pd.DataFrame([all_models[i].predict_proba(X_test_for_sub)[:,1] for i in range(1, len(all_models), 3)]).mean(axis=0)\n",
    "    all_predicted_vals_bc = pd.DataFrame([all_models[i].predict(X_test_for_sub) for i in range(2, len(all_models), 3)]).mean(axis=0)\n",
    "    all_values_predicted = pd.concat([all_predicted_vals_rf,all_predicted_vals_lr, all_predicted_vals_bc], axis=1).mean(axis=1)\n",
    "    acc_with_sub_samp.append({\n",
    "        'rf_gini': gini_normalized(y_test_for_sub, all_predicted_vals_rf),\n",
    "        'lr_gini': gini_normalized(y_test_for_sub, all_predicted_vals_lr),\n",
    "        'bc_gini': gini_normalized(y_test_for_sub, all_predicted_vals_bc),\n",
    "        'averaged': gini_normalized(y_test_for_sub,all_values_predicted)\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averaged</th>\n",
       "      <th>bc_gini</th>\n",
       "      <th>lr_gini</th>\n",
       "      <th>rf_gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255151</td>\n",
       "      <td>0.157132</td>\n",
       "      <td>0.252415</td>\n",
       "      <td>0.156841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249068</td>\n",
       "      <td>0.151016</td>\n",
       "      <td>0.252121</td>\n",
       "      <td>0.155272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230510</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.229635</td>\n",
       "      <td>0.163730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235002</td>\n",
       "      <td>0.155562</td>\n",
       "      <td>0.228198</td>\n",
       "      <td>0.140790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238146</td>\n",
       "      <td>0.140436</td>\n",
       "      <td>0.240538</td>\n",
       "      <td>0.149440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.243857</td>\n",
       "      <td>0.144852</td>\n",
       "      <td>0.243409</td>\n",
       "      <td>0.159457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239681</td>\n",
       "      <td>0.156499</td>\n",
       "      <td>0.236141</td>\n",
       "      <td>0.163166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.239429</td>\n",
       "      <td>0.153807</td>\n",
       "      <td>0.231204</td>\n",
       "      <td>0.160510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.254107</td>\n",
       "      <td>0.159629</td>\n",
       "      <td>0.256301</td>\n",
       "      <td>0.164851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.242820</td>\n",
       "      <td>0.150408</td>\n",
       "      <td>0.247106</td>\n",
       "      <td>0.158329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   averaged   bc_gini   lr_gini   rf_gini\n",
       "0  0.255151  0.157132  0.252415  0.156841\n",
       "1  0.249068  0.151016  0.252121  0.155272\n",
       "2  0.230510  0.147700  0.229635  0.163730\n",
       "3  0.235002  0.155562  0.228198  0.140790\n",
       "4  0.238146  0.140436  0.240538  0.149440\n",
       "5  0.243857  0.144852  0.243409  0.159457\n",
       "6  0.239681  0.156499  0.236141  0.163166\n",
       "7  0.239429  0.153807  0.231204  0.160510\n",
       "8  0.254107  0.159629  0.256301  0.164851\n",
       "9  0.242820  0.150408  0.247106  0.158329"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(acc_with_sub_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate test dataset **\n",
    "\n",
    "Stick with method above except this time evaluate how well it does on the real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('b', 0)\n",
      "('b', 1)\n",
      "('b', 2)\n",
      "('b', 3)\n",
      "('b', 4)\n",
      "('b', 5)\n",
      "('b', 6)\n",
      "('b', 7)\n",
      "('b', 8)\n",
      "('b', 9)\n",
      "('b', 10)\n",
      "('b', 11)\n",
      "('b', 12)\n",
      "('b', 13)\n",
      "('b', 14)\n",
      "('b', 15)\n",
      "('b', 16)\n",
      "('b', 17)\n",
      "('b', 18)\n",
      "('b', 19)\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "max_values = 10000\n",
    "for __ in range(20):\n",
    "    print('b', __)\n",
    "    # create series of subsampled datasets\n",
    "    assert ((df_train_copy.index != df_train_copy.index).sum() == 0)\n",
    "    sampled_indexes = np.hstack(list(pd.DataFrame(df_train_copy['target']).groupby(by='target').apply(lambda x: x.sample(min(max_values, x.shape[0])).index)))\n",
    "\n",
    "    new_x_train = df_train_copy.loc[sampled_indexes]\n",
    "    new_y_train = df_train_copy.loc[sampled_indexes]['target']\n",
    "    \n",
    "    all_models.extend(\n",
    "        [\n",
    "            # train each subsampled model\n",
    "            pipe_rf.fit(new_x_train, new_y_train),\n",
    "            pipe_lr.fit(new_x_train, new_y_train),\n",
    "            pipe_bc.fit(new_x_train, new_y_train)\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_02_cat\n",
      "ps_ind_04_cat\n",
      "ps_ind_05_cat\n",
      "ps_reg_03\n",
      "ps_car_01_cat\n",
      "ps_car_02_cat\n",
      "ps_car_03_cat\n",
      "ps_car_05_cat\n",
      "ps_car_07_cat\n",
      "ps_car_09_cat\n",
      "ps_car_11\n",
      "ps_car_14\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../../test.csv', index_col=0)\n",
    "df_test.replace(-1, np.nan, inplace=True)\n",
    "df_test_copy = df_test.copy()\n",
    "for c in df_test.columns:\n",
    "    total_num = df_test[c].isnull().sum()\n",
    "    if(total_num == 0):\n",
    "        continue\n",
    "    print(c)    \n",
    "    random_vals = np.random.choice(list(value_count_columns[c].index), total_num, list(value_count_columns[c].values))\n",
    "    df_test_copy[c].loc[df_test[c].isnull()] = random_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # fit data using all subsamples\n",
    "df_test_all_predicted_vals_rf = pd.DataFrame([all_models[i].predict(df_test_copy) for i in range(0, len(all_models), 3)]).mean(axis=0)\n",
    "# or choose argmax....??\n",
    "df_test_all_predicted_vals_lr = pd.DataFrame([all_models[i].predict_proba(df_test_copy)[:,1] for i in range(1, len(all_models), 3)]).mean(axis=0)\n",
    "df_test_all_predicted_vals_bc = pd.DataFrame([all_models[i].predict(df_test_copy) for i in range(2, len(all_models), 3)]).mean(axis=0)\n",
    "\n",
    "df_test_all_values_predicted = pd.concat(\n",
    "    [df_test_all_predicted_vals_rf,df_test_all_predicted_vals_lr, df_test_all_predicted_vals_bc], axis=1\n",
    ").mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.141361\n",
       "1         0.150017\n",
       "2         0.480311\n",
       "3         0.115642\n",
       "4         0.498543\n",
       "5         0.159062\n",
       "6         0.161345\n",
       "7         0.463788\n",
       "8         0.878808\n",
       "9         0.879075\n",
       "10        0.148392\n",
       "11        0.128527\n",
       "12        0.199561\n",
       "13        0.870162\n",
       "14        0.524938\n",
       "15        0.144294\n",
       "16        0.169487\n",
       "17        0.813746\n",
       "18        0.101367\n",
       "19        0.879613\n",
       "20        0.481535\n",
       "21        0.512359\n",
       "22        0.847146\n",
       "23        0.108962\n",
       "24        0.160101\n",
       "25        0.130096\n",
       "26        0.908189\n",
       "27        0.499367\n",
       "28        0.490589\n",
       "29        0.133205\n",
       "            ...   \n",
       "892786    0.131552\n",
       "892787    0.156015\n",
       "892788    0.836491\n",
       "892789    0.157008\n",
       "892790    0.502249\n",
       "892791    0.122191\n",
       "892792    0.127930\n",
       "892793    0.506299\n",
       "892794    0.486426\n",
       "892795    0.147162\n",
       "892796    0.179320\n",
       "892797    0.551693\n",
       "892798    0.536903\n",
       "892799    0.834557\n",
       "892800    0.832582\n",
       "892801    0.469978\n",
       "892802    0.145995\n",
       "892803    0.811452\n",
       "892804    0.122176\n",
       "892805    0.159644\n",
       "892806    0.136277\n",
       "892807    0.185107\n",
       "892808    0.472111\n",
       "892809    0.107583\n",
       "892810    0.131097\n",
       "892811    0.892407\n",
       "892812    0.852373\n",
       "892813    0.473241\n",
       "892814    0.128304\n",
       "892815    0.491327\n",
       "dtype: float64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_all_values_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_test_all_values_predicted.values, index=df_test.index, columns=['target']).to_csv('submission_test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Final prediction is 0.234 with test data which is slightly similar to what we were predicting from train_test_split*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic point, simply using undersampling to rebalance data shows boost in gini accuracy based on simple train_test_split\n",
    "\n",
    "** Next steps **\n",
    "\n",
    "Need to proceed and try on the **imblearn library**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
